{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect and Mitigate Unfairness in Models\n",
    "\n",
    "Machine learning models can incorporate unintentional bias, which can lead to issues with *fairness*. For example, a model that predicts the likelihood of diabetes might work well for some age groups, but not for others - subjecting a subset of patients to unnecessary tests, or depriving them of tests that would confirm a diabetes diagnosis.\n",
    "\n",
    "In this notebook, you'll use the **Fairlearn** package to analyze a model and explore disparity in prediction performance for different subsets of patients based on age.\n",
    "\n",
    "> **Note**: Integration with the Fairlearn package is in preview at this time. You may experience some unexpected errors.\n",
    "\n",
    "## Important - Considerations for fairness\n",
    "\n",
    "> This notebook is designed as a practical exercise to help you explore the Fairlearn package and its integration with Azure Machine Learning. However, there are a great number of considerations that an organization or data science team must discuss related to fairness before using the tools. Fairness is a complex *sociotechnical* challenge that goes beyond simply running a tool to analyze models.\n",
    ">\n",
    "> Microsoft Research has co-developed a [fairness checklist](https://www.microsoft.com/en-us/research/publication/co-designing-checklists-to-understand-organizational-challenges-and-opportunities-around-fairness-in-ai/) that provides a great starting point for the important discussions that need to take place before a single line of code is written.\n",
    "\n",
    "## Install the required SDKs\n",
    "\n",
    "To use the Fairlearn package with Azure Machine Learning, you need the Azure Machine Learning and Fairlearn Python packages, so run the following cell verify that the **azureml-contrib-fairness** package is installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: azureml-contrib-fairness\n",
      "Version: 1.35.0\n",
      "Summary: Uploads fairness dashboards to AzureML (preview).\n",
      "Home-page: https://docs.microsoft.com/python/api/overview/azure/ml/?view=azure-ml-py\n",
      "Author: Microsoft Corp\n",
      "Author-email: None\n",
      "License: Proprietary https://aka.ms/azureml-preview-sdk-license \n",
      "Location: c:\\users\\rgkal\\anaconda3\\lib\\site-packages\n",
      "Requires: jsonschema, azureml-core\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show azureml-contrib-fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll also need the **fairlearn** package itself, and the **raiwidgets** package (which is used by Fairlearn to visualize dashboards). Run the following cell to install them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: fairlearn==0.7.0 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (0.7.0)\n",
      "Requirement already up-to-date: raiwidgets in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied, skipping upgrade: pandas>=0.25.1 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from fairlearn==0.7.0) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17.2 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from fairlearn==0.7.0) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.4.1 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from fairlearn==0.7.0) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.22.1 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from fairlearn==0.7.0) (0.22.1)\n",
      "Requirement already satisfied, skipping upgrade: lightgbm>=2.0.11 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from raiwidgets) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: ipykernel<6.0 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from raiwidgets) (5.1.4)\n",
      "Requirement already satisfied, skipping upgrade: jinja2==2.11.3 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from raiwidgets) (2.11.3)\n",
      "Requirement already satisfied, skipping upgrade: rai-core-flask==0.2.4 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from raiwidgets) (0.2.4)\n",
      "Requirement already satisfied, skipping upgrade: responsibleai==0.13.0 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from raiwidgets) (0.13.0)\n",
      "Requirement already satisfied, skipping upgrade: erroranalysis>=0.1.24 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from raiwidgets) (0.1.25)\n",
      "Requirement already satisfied, skipping upgrade: ipython==7.16.1 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from raiwidgets) (7.16.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from pandas>=0.25.1->fairlearn==0.7.0) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from pandas>=0.25.1->fairlearn==0.7.0) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.1->fairlearn==0.7.0) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: traitlets>=4.1.0 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from ipykernel<6.0->raiwidgets) (4.3.3)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=4.2 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from ipykernel<6.0->raiwidgets) (6.0.3)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-client in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from ipykernel<6.0->raiwidgets) (5.3.4)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from jinja2==2.11.3->raiwidgets) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: Flask-Cors==3.0.9 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from rai-core-flask==0.2.4->raiwidgets) (3.0.9)\n",
      "Requirement already satisfied, skipping upgrade: greenlet==0.4.17 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from rai-core-flask==0.2.4->raiwidgets) (0.4.17)\n",
      "Requirement already satisfied, skipping upgrade: Flask~=1.0.0 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from rai-core-flask==0.2.4->raiwidgets) (1.0.3)\n",
      "Requirement already satisfied, skipping upgrade: gevent==20.9.0 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from rai-core-flask==0.2.4->raiwidgets) (20.9.0)\n",
      "Requirement already satisfied, skipping upgrade: semver~=2.13.0 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from responsibleai==0.13.0->raiwidgets) (2.13.0)\n",
      "Requirement already satisfied, skipping upgrade: interpret-community>=0.20.0 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from responsibleai==0.13.0->raiwidgets) (0.20.0)\n",
      "Requirement already satisfied, skipping upgrade: econml~=0.12.0 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from responsibleai==0.13.0->raiwidgets) (0.12.0)\n",
      "Requirement already satisfied, skipping upgrade: networkx<=2.5 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from responsibleai==0.13.0->raiwidgets) (2.4)\n",
      "Requirement already satisfied, skipping upgrade: dice-ml<0.8,>=0.7.2 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from responsibleai==0.13.0->raiwidgets) (0.7.2)\n",
      "Requirement already satisfied, skipping upgrade: pygments in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from ipython==7.16.1->raiwidgets) (2.5.2)\n",
      "Requirement already satisfied, skipping upgrade: jedi>=0.10 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from ipython==7.16.1->raiwidgets) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: backcall in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from ipython==7.16.1->raiwidgets) (0.1.0)\n",
      "Requirement already satisfied, skipping upgrade: decorator in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from ipython==7.16.1->raiwidgets) (4.4.1)\n",
      "Requirement already satisfied, skipping upgrade: colorama; sys_platform == \"win32\" in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from ipython==7.16.1->raiwidgets) (0.4.3)\n",
      "Requirement already satisfied, skipping upgrade: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from ipython==7.16.1->raiwidgets) (3.0.3)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=18.5 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from ipython==7.16.1->raiwidgets) (45.2.0.post20200210)\n",
      "Requirement already satisfied, skipping upgrade: pickleshare in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from ipython==7.16.1->raiwidgets) (0.7.5)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas>=0.25.1->fairlearn==0.7.0) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: ipython-genutils in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from traitlets>=4.1.0->ipykernel<6.0->raiwidgets) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: pyzmq>=13 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel<6.0->raiwidgets) (18.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pywin32>=1.0; sys_platform == \"win32\" in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel<6.0->raiwidgets) (227)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-core>=4.6.0 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel<6.0->raiwidgets) (4.6.1)\n",
      "Requirement already satisfied, skipping upgrade: Werkzeug>=0.14 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from Flask~=1.0.0->rai-core-flask==0.2.4->raiwidgets) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: click>=5.1 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from Flask~=1.0.0->rai-core-flask==0.2.4->raiwidgets) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from Flask~=1.0.0->rai-core-flask==0.2.4->raiwidgets) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: cffi>=1.12.2; platform_python_implementation == \"CPython\" and sys_platform == \"win32\" in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from gevent==20.9.0->rai-core-flask==0.2.4->raiwidgets) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: zope.event in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from gevent==20.9.0->rai-core-flask==0.2.4->raiwidgets) (4.5.0)\n",
      "Requirement already satisfied, skipping upgrade: zope.interface in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from gevent==20.9.0->rai-core-flask==0.2.4->raiwidgets) (5.4.0)\n",
      "Requirement already satisfied, skipping upgrade: packaging in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from interpret-community>=0.20.0->responsibleai==0.13.0->raiwidgets) (20.1)\n",
      "Requirement already satisfied, skipping upgrade: numba<0.54.0 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from interpret-community>=0.20.0->responsibleai==0.13.0->raiwidgets) (0.48.0)\n",
      "Requirement already satisfied, skipping upgrade: interpret-core[required]<=0.2.5,>=0.1.20 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from interpret-community>=0.20.0->responsibleai==0.13.0->raiwidgets) (0.2.5)\n",
      "Requirement already satisfied, skipping upgrade: shap<=0.39.0,>=0.20.0 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from interpret-community>=0.20.0->responsibleai==0.13.0->raiwidgets) (0.39.0)\n",
      "Requirement already satisfied, skipping upgrade: dowhy in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from econml~=0.12.0->responsibleai==0.13.0->raiwidgets) (0.6)\n",
      "Requirement already satisfied, skipping upgrade: sparse in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from econml~=0.12.0->responsibleai==0.13.0->raiwidgets) (0.13.0)\n",
      "Requirement already satisfied, skipping upgrade: statsmodels>=0.10 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from econml~=0.12.0->responsibleai==0.13.0->raiwidgets) (0.10.2)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from dice-ml<0.8,>=0.7.2->responsibleai==0.13.0->raiwidgets) (4.42.1)\n",
      "Requirement already satisfied, skipping upgrade: h5py in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from dice-ml<0.8,>=0.7.2->responsibleai==0.13.0->raiwidgets) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from dice-ml<0.8,>=0.7.2->responsibleai==0.13.0->raiwidgets) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: parso>=0.5.0 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython==7.16.1->raiwidgets) (0.5.2)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.16.1->raiwidgets) (0.1.8)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from cffi>=1.12.2; platform_python_implementation == \"CPython\" and sys_platform == \"win32\"->gevent==20.9.0->rai-core-flask==0.2.4->raiwidgets) (2.19)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from packaging->interpret-community>=0.20.0->responsibleai==0.13.0->raiwidgets) (2.4.6)\n",
      "Requirement already satisfied, skipping upgrade: llvmlite<0.32.0,>=0.31.0dev0 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from numba<0.54.0->interpret-community>=0.20.0->responsibleai==0.13.0->raiwidgets) (0.31.0)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from shap<=0.39.0,>=0.20.0->interpret-community>=0.20.0->responsibleai==0.13.0->raiwidgets) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: slicer==0.0.7 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from shap<=0.39.0,>=0.20.0->interpret-community>=0.20.0->responsibleai==0.13.0->raiwidgets) (0.0.7)\n",
      "Requirement already satisfied, skipping upgrade: sympy>=1.4 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from dowhy->econml~=0.12.0->responsibleai==0.13.0->raiwidgets) (1.5.1)\n",
      "Requirement already satisfied, skipping upgrade: pydot>=1.4 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from dowhy->econml~=0.12.0->responsibleai==0.13.0->raiwidgets) (1.4.2)\n",
      "Requirement already satisfied, skipping upgrade: patsy>=0.4.0 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from statsmodels>=0.10->econml~=0.12.0->responsibleai==0.13.0->raiwidgets) (0.5.1)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from jsonschema->dice-ml<0.8,>=0.7.2->responsibleai==0.13.0->raiwidgets) (0.15.7)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from jsonschema->dice-ml<0.8,>=0.7.2->responsibleai==0.13.0->raiwidgets) (21.2.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from jsonschema->dice-ml<0.8,>=0.7.2->responsibleai==0.13.0->raiwidgets) (4.6.4)\n",
      "Requirement already satisfied, skipping upgrade: mpmath>=0.19 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from sympy>=1.4->dowhy->econml~=0.12.0->responsibleai==0.13.0->raiwidgets) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema->dice-ml<0.8,>=0.7.2->responsibleai==0.13.0->raiwidgets) (3.10.0.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in c:\\users\\rgkal\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema->dice-ml<0.8,>=0.7.2->responsibleai==0.13.0->raiwidgets) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade fairlearn==0.7.0 raiwidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model\n",
    "\n",
    "You'll start by training a classification model to predict the likelihood of diabetes. In addition to splitting the data into training and test sets of features and labels, you'll extract *sensitive* features that are used to define subpopulations of the data for which you want to compare fairness. In this case, you'll use the **Age** column to define two categories of patient: those over 50 years old, and those 50 or younger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "Training model...\n",
      "Model trained.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "data = pd.read_csv('data/diabetes.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "features = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']\n",
    "X, y = data[features].values, data['Diabetic'].values\n",
    "\n",
    "# Get sensitive features\n",
    "S = data[['Age']].astype(int)\n",
    "# Change value to represent age groups\n",
    "S['Age'] = np.where(S.Age > 50, 'Over 50', '50 or younger')\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test, S_train, S_test = train_test_split(X, y, S, test_size=0.20, random_state=0, stratify=y)\n",
    "\n",
    "# Train a classification model\n",
    "print(\"Training model...\")\n",
    "diabetes_model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've trained a model, you can use the Fairlearn package to compare its behavior for different sensitive feature values. In this case, you'll:\n",
    "\n",
    "- Use the fairlearn **selection_rate** function to return the selection rate (percentage of positive predictions) for the overall population.\n",
    "- Use **scikit-learn** metric functions to calculate overall accuracy, recall, and precision metrics.\n",
    "- Use a **MetricFrame** to calculate selection rate, accuracy, recall, and precision for each age group in the **Age** sensitive feature. Note that a mix of **fairlearn** and **scikit-learn** metric functions are used to calculate the performance values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Metrics:\n",
      "\tSelection Rate: 0.335\n",
      "\tAccuracy: 0.8905\n",
      "\tRecall: 0.8370702541106129\n",
      "\tPrecision: 0.835820895522388\n",
      "\n",
      "Metrics by Group:\n",
      "              selection_rate  accuracy    recall precision\n",
      "Age                                                       \n",
      "50 or younger       0.297073  0.891773  0.816667  0.819703\n",
      "Over 50             0.698413  0.878307  0.922481  0.901515\n"
     ]
    }
   ],
   "source": [
    "from fairlearn.metrics import selection_rate, MetricFrame\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "\n",
    "# Get predictions for the witheld test data\n",
    "y_hat = diabetes_model.predict(X_test)\n",
    "\n",
    "# Get overall metrics\n",
    "print(\"Overall Metrics:\")\n",
    "# Get selection rate from fairlearn\n",
    "overall_selection_rate = selection_rate(y_test, y_hat) # Get selection rate from fairlearn\n",
    "print(\"\\tSelection Rate:\", overall_selection_rate)\n",
    "# Get standard metrics from scikit-learn\n",
    "overall_accuracy = accuracy_score(y_test, y_hat)\n",
    "print(\"\\tAccuracy:\", overall_accuracy)\n",
    "overall_recall = recall_score(y_test, y_hat)\n",
    "print(\"\\tRecall:\", overall_recall)\n",
    "overall_precision = precision_score(y_test, y_hat)\n",
    "print(\"\\tPrecision:\", overall_precision)\n",
    "\n",
    "# Get metrics by sensitive group from fairlearn\n",
    "print('\\nMetrics by Group:')\n",
    "metrics = {'selection_rate': selection_rate,\n",
    "           'accuracy': accuracy_score,\n",
    "           'recall': recall_score,\n",
    "           'precision': precision_score}\n",
    "\n",
    "group_metrics = MetricFrame(metrics=metrics,\n",
    "                             y_true=y_test,\n",
    "                             y_pred=y_hat,\n",
    "                             sensitive_features=S_test['Age'])\n",
    "\n",
    "print(group_metrics.by_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these metrics, you should be able to discern that a larger proportion of the older patients are predicted to be diabetic. *Accuracy* should be more or less equal for the two groups, but a closer inspection of *precision* and *recall* indicates some disparity in how well the model predicts for each age group.\n",
    "\n",
    "In this scenario, consider *recall*. This metric indicates the proportion of positive cases that were correctly identified by the model. In other words, of all the patients who are actually diabetic, how many did the model find? The model does a better job of this for patients in the older age group than for younger patients.\n",
    "\n",
    "It's often easier to compare metrics visually. To do this, you'll use the Fairlearn fairness dashboard:\n",
    "\n",
    "1. Run the cell below to generate a dashboard from the model you created previously.\n",
    "2. When the widget is displayed, use the **Get started** link to start configuring your visualization.\n",
    "3. Select the sensitive features you want to compare (in this case, there's only one: **Age**).\n",
    "4. Select the model performance metric you want to compare (in this case, it's a binary classification model so the options are *Accuracy*, *Balanced accuracy*, *Precision*, and *Recall*). Start with **Recall**.\n",
    "5. Select the type of fairness comparison you want to view. Start with **Demographic parity difference**.\n",
    "6. View the dashboard visualization, which shows:\n",
    "    - **Disparity in performance** - how the selected performance metric compares for the subpopulations, including *underprediction* (false negatives) and *overprediction* (false positives).\n",
    "    - **Disparity in predictions** - A comparison of the number of positive cases per subpopulation.\n",
    "7. Edit the configuration to compare the predictions based on different performance and fairness metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numba.core'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8f830d3cf999>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mraiwidgets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFairnessDashboard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# View this model in Fairlearn's fairness dashboard, and see the disparities which appear:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m FairnessDashboard(sensitive_features=S_test,\n\u001b[0;32m      5\u001b[0m                    \u001b[0my_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\raiwidgets\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;34m\"\"\"Package for the fairness, explanation, and error analysis widgets.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfairness_dashboard\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFairnessDashboard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexplanation_dashboard\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExplanationDashboard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0merror_analysis_dashboard\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mErrorAnalysisDashboard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\raiwidgets\\fairness_dashboard.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;34m\"\"\"Defines the fairness dashboard class.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdashboard\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDashboard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfairness_metric_calculation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFairnessMetricModule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mresponsibleai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_processing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_convert_to_string_list_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\raiwidgets\\dashboard.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrai_core_flask\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFlaskHelper\u001b[0m  \u001b[1;31m# , environment_detector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mresponsibleai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialization_utilities\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mserialize_json_safe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\responsibleai\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;34m\"\"\"Responsible AI SDK package.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mresponsibleai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodelanalysis\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelAnalysis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModelTask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\responsibleai\\modelanalysis\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;34m\"\"\"Implementation of Model Analysis API.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mresponsibleai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodelanalysis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_analysis\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelAnalysis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mresponsibleai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodelanalysis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelTask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\responsibleai\\modelanalysis\\model_analysis.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mresponsibleai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_analysis_manager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mErrorAnalysisManager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mresponsibleai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplainer_manager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExplainerManager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mresponsibleai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcausal_manager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCausalManager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mresponsibleai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mUserConfigValidationException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mresponsibleai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodelanalysis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelTask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\responsibleai\\_managers\\causal_manager.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0meconml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcausal_analysis\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCausalAnalysis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\econml\\solutions\\causal_analysis\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Licensed under the MIT License.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_causal_analysis\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCausalAnalysis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"CausalAnalysis\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\econml\\solutions\\causal_analysis\\_causal_analysis.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0merase_traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numba.core'"
     ]
    }
   ],
   "source": [
    "from raiwidgets import FairnessDashboard\n",
    "\n",
    "# View this model in Fairlearn's fairness dashboard, and see the disparities which appear:\n",
    "FairnessDashboard(sensitive_features=S_test,\n",
    "                   y_true=y_test,\n",
    "                   y_pred={\"diabetes_model\": diabetes_model.predict(X_test)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show a much higher selection rate for patients over 50 than for younger patients. However, in reality, age is a genuine factor in diabetes, so you would expect more positive cases among older patients.\n",
    "\n",
    "If we base model performance on *accuracy* (in other words, the percentage of predictions the model gets right), then it seems to work more or less equally for both subpopulations. However, based on the *precision* and *recall* metrics, the model tends to perform better for patients who are over 50 years old.\n",
    "\n",
    "Let's see what happens if we exclude the **Age** feature when training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "ageless = features.copy()\n",
    "ageless.remove('Age')\n",
    "X2, y2 = data[ageless].values, data['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train2, X_test2, y_train2, y_test2, S_train2, S_test2 = train_test_split(X2, y2, S, test_size=0.20, random_state=0, stratify=y2)\n",
    "\n",
    "# Train a classification model\n",
    "print(\"Training model...\")\n",
    "ageless_model = DecisionTreeClassifier().fit(X_train2, y_train2)\n",
    "print(\"Model trained.\")\n",
    "\n",
    "# View this model in Fairlearn's fairness dashboard, and see the disparities which appear:\n",
    "FairnessDashboard(sensitive_features=S_test2,\n",
    "                   y_true=y_test2,\n",
    "                   y_pred={\"ageless_diabetes_model\": ageless_model.predict(X_test2)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the model in the dashboard.\n",
    "\n",
    "When you review *recall*, note that the disparity has reduced, but the overall recall has also reduced because the model now significantly underpredicts positive cases for older patients. Even though **Age** was not a feature used in training, the model still exhibits some disparity in how well it predicts for older and younger patients.\n",
    "\n",
    "In this scenario, simply removing the **Age** feature slightly reduces the disparity in *recall*, but increases the disparity in *precision* and *accuracy*. This underlines one the key difficulties in applying fairness to machine learning models - you must be clear about what *fairness* means in a particular context, and optimize for that.\n",
    "\n",
    "## Register the model and upload the dashboard data to your workspace\n",
    "\n",
    "You've trained the model and reviewed the dashboard locally in this notebook; but it might be useful to register the model in your Azure Machine Learning workspace and create an experiment to record the dashboard data so you can track and share your fairness analysis.\n",
    "\n",
    "Let's start by registering the original model (which included **Age** as a feature).\n",
    "\n",
    "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Model\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Load the Azure ML workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to work with', ws.name)\n",
    "\n",
    "# Save the trained model\n",
    "model_file = 'diabetes_model.pkl'\n",
    "joblib.dump(value=diabetes_model, filename=model_file)\n",
    "\n",
    "# Register the model\n",
    "print('Registering model...')\n",
    "registered_model = Model.register(model_path=model_file,\n",
    "                                  model_name='diabetes_classifier',\n",
    "                                  workspace=ws)\n",
    "model_id= registered_model.id\n",
    "\n",
    "\n",
    "print('Model registered.', model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use the FairLearn package to create binary classification group metric sets for one or more models, and use an Azure Machine Learning experiment to upload the metrics.\n",
    "\n",
    "> **Note**: This may take a while, and may result in some warning messages (which you can ignore). When the experiment has completed, the dashboard data will be downloaded and displayed to verify that it was uploaded successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.metrics._group_metric_set import _create_group_metric_set\n",
    "from azureml.contrib.fairness import upload_dashboard_dictionary, download_dashboard_by_upload_id\n",
    "\n",
    "#  Create a dictionary of model(s) you want to assess for fairness \n",
    "sf = { 'Age': S_test.Age}\n",
    "ys_pred = { model_id:diabetes_model.predict(X_test) }\n",
    "dash_dict = _create_group_metric_set(y_true=y_test,\n",
    "                                    predictions=ys_pred,\n",
    "                                    sensitive_features=sf,\n",
    "                                    prediction_type='binary_classification')\n",
    "\n",
    "exp = Experiment(ws, 'mslearn-diabetes-fairness')\n",
    "print(exp)\n",
    "\n",
    "run = exp.start_logging()\n",
    "\n",
    "# Upload the dashboard to Azure Machine Learning\n",
    "try:\n",
    "    dashboard_title = \"Fairness insights of Diabetes Classifier\"\n",
    "    upload_id = upload_dashboard_dictionary(run,\n",
    "                                            dash_dict,\n",
    "                                            dashboard_name=dashboard_title)\n",
    "    print(\"\\nUploaded to id: {0}\\n\".format(upload_id))\n",
    "\n",
    "    # To test the dashboard, you can download it\n",
    "    downloaded_dict = download_dashboard_by_upload_id(run, upload_id)\n",
    "    print(downloaded_dict)\n",
    "finally:\n",
    "    run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preceding code downloaded the metrics generated in the experiement just to confirm it completed successfully. The real benefit of uploading the metrics to an experiement is that you can now view the FairLearn dashboard in Azure Machine Learning studio.\n",
    "\n",
    "Run the cell below to see the experiment details, and click the **View Run details** link in the widget to see the run in Azure Machine Learning studio. Then view the **Fairness** tab of the experiment run to view the dashboard for the fairness ID assigned to the metrics you uploaded, which behaves the same way as the widget you viewed previously in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also find the fairness dashboard by selecting a model in the **Models** page of Azure Machine Learning studio and reviewing its **Fairness** tab. This enables your organization to maintain a log of fairness analysis for the models you train and register."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigate unfairness in the model\n",
    "\n",
    "Now that you've analyzed the model for fairness, you can use any of the *mitigation* techniques supported by the FairLearn package to find a model that balances predictive performance and fairness.\n",
    "\n",
    "In this exercise, you'll use the **GridSearch** feature, which trains multiple models in an attempt to minimize the disparity of predictive performance for the sensitive features in the dataset (in this case, the age groups). You'll optimize the models by applying the **EqualizedOdds** parity constraint, which tries to ensure that models that exhibit similar true and false positive rates for each sensitive feature grouping. \n",
    "\n",
    "> *This may take some time to run*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.reductions import GridSearch, EqualizedOdds\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "print('Finding mitigated models...')\n",
    "\n",
    "# Train multiple models\n",
    "sweep = GridSearch(DecisionTreeClassifier(),\n",
    "                   constraints=EqualizedOdds(),\n",
    "                   grid_size=20)\n",
    "\n",
    "sweep.fit(X_train, y_train, sensitive_features=S_train.Age)\n",
    "models = sweep.predictors_\n",
    "\n",
    "# Save the models and get predictions from them (plus the original unmitigated one for comparison)\n",
    "model_dir = 'mitigated_models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model_name = 'diabetes_unmitigated'\n",
    "print(model_name)\n",
    "joblib.dump(value=diabetes_model, filename=os.path.join(model_dir, '{0}.pkl'.format(model_name)))\n",
    "predictions = {model_name: diabetes_model.predict(X_test)}\n",
    "i = 0\n",
    "for model in models:\n",
    "    i += 1\n",
    "    model_name = 'diabetes_mitigated_{0}'.format(i)\n",
    "    print(model_name)\n",
    "    joblib.dump(value=model, filename=os.path.join(model_dir, '{0}.pkl'.format(model_name)))\n",
    "    predictions[model_name] = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use the FairLearn dashboard to compare the mitigated models:\n",
    "\n",
    "Run the following cell and then use the wizard to visualize **Age** by **Recall**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FairnessDashboard(sensitive_features=S_test,\n",
    "                   y_true=y_test,\n",
    "                   y_pred=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models are shown on a scatter plot. You can compare the models by measuring the disparity in predictions (in other words, the selection rate) or the disparity in the selected performance metric (in this case, *recall*). In this scenario, we expect disparity in selection rates (because we know that age *is* a factor in diabetes, with more positive cases in the older age group). What we're interested in is the disparity in predictive performance, so select the option to measure **Disparity in recall**.\n",
    "\n",
    "The chart shows clusters of models with the overall *recall* metric on the X axis, and the disparity in recall on the Y axis. Therefore, the ideal model (with high recall and low disparity) would be at the bottom right corner of the plot. You can choose the right balance of predictive performance and fairness for your particular needs, and select an appropriate model to see its details.\n",
    "\n",
    "An important point to reinforce is that applying fairness mitigation to a model is a trade-off between overall predictive performance and disparity across sensitive feature groups - generally you must sacrifice some overall predictive performance to ensure that the model predicts fairly for all segments of the population.\n",
    "\n",
    "> **Note**: Viewing the *precision* metric may result in a warning that precision is being set to 0.0 due to no predicted samples - you can ignore this.\n",
    "\n",
    "## Upload the mitigation dashboard metrics to Azure Machine Learning\n",
    "\n",
    "As before, you might want to keep track of your mitigation experimentation. To do this, you can:\n",
    "\n",
    "1. Register the models found by the GridSearch process.\n",
    "2. Compute the performance and disparity metrics for the models.\n",
    "3. Upload the metrics in an Azure Machine Learning experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the models\n",
    "registered_model_predictions = dict()\n",
    "for model_name, prediction_data in predictions.items():\n",
    "    model_file = os.path.join(model_dir, model_name + \".pkl\")\n",
    "    registered_model = Model.register(model_path=model_file,\n",
    "                                      model_name=model_name,\n",
    "                                      workspace=ws)\n",
    "    registered_model_predictions[registered_model.id] = prediction_data\n",
    "\n",
    "#  Create a group metric set for binary classification based on the Age feature for all of the models\n",
    "sf = { 'Age': S_test.Age}\n",
    "dash_dict = _create_group_metric_set(y_true=y_test,\n",
    "                                     predictions=registered_model_predictions,\n",
    "                                     sensitive_features=sf,\n",
    "                                     prediction_type='binary_classification')\n",
    "\n",
    "exp = Experiment(ws, \"mslearn-diabetes-fairness\")\n",
    "print(exp)\n",
    "\n",
    "run = exp.start_logging()\n",
    "RunDetails(run).show()\n",
    "\n",
    "# Upload the dashboard to Azure Machine Learning\n",
    "try:\n",
    "    dashboard_title = \"Fairness Comparison of Diabetes Models\"\n",
    "    upload_id = upload_dashboard_dictionary(run,\n",
    "                                            dash_dict,\n",
    "                                            dashboard_name=dashboard_title)\n",
    "    print(\"\\nUploaded to id: {0}\\n\".format(upload_id))\n",
    "finally:\n",
    "    run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: A warning that precision is being set to 0.0 due to no predicted samples may be displayed - you can ignore this.\n",
    "\n",
    "\n",
    "When the experiment has finished running, click the **View Run details** link in the widget to view the run in Azure Machine Learning studio (you may need to scroll past the initial output to see the widget), and view the FairLearn dashboard on the **fairness** tab."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e0679b8d713c70730f1507de8189a78c48c46b2c858e2faf98d8f424ca3d7b96"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
